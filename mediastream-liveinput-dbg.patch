diff --git a/CMakeLists.txt b/CMakeLists.txt
index 18bfcd4..cccaeb8 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -1,3 +1,4 @@
 cmake_minimum_required(VERSION 2.8)
+#set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wall -std=gnu++0x -g")
 set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wall -std=gnu++0x")
 add_subdirectory(src)
diff --git a/src/ContentsInjectedBundle/audio/AudioDestination.cpp b/src/ContentsInjectedBundle/audio/AudioDestination.cpp
index 2ebcd3a..8d764a1 100644
--- a/src/ContentsInjectedBundle/audio/AudioDestination.cpp
+++ b/src/ContentsInjectedBundle/audio/AudioDestination.cpp
@@ -24,6 +24,7 @@
 
 using namespace Nix;
 
+static gboolean messageCallback(GstBus*, GstMessage* message, GstElement*);
 static bool configureSinkDevice(GstElement* autoSink);
 
 #ifndef GST_API_VERSION_1
@@ -43,6 +44,11 @@ AudioDestination::AudioDestination(size_t bufferSize, unsigned numberOfInputChan
 
     m_pipeline = gst_pipeline_new("play");
 
+    GstBus* bus = gst_pipeline_get_bus(GST_PIPELINE(m_pipeline));
+    assert(bus);
+    gst_bus_add_signal_watch(bus);
+    g_signal_connect(bus, "message", G_CALLBACK(messageCallback), m_pipeline);
+
     GstElement* webkitAudioSrc = reinterpret_cast<GstElement*>(g_object_new(WEBKIT_TYPE_WEB_AUDIO_SRC,
                                                                             "rate", sampleRate,
                                                                             "handler", callback,
@@ -157,3 +163,51 @@ static bool configureSinkDevice(GstElement* autoSink) {
     return true;
 }
 
+static gboolean messageCallback(GstBus*, GstMessage* message, GstElement* data)
+{
+    GError* error = 0;
+    gchar* debug = 0;
+
+    switch (GST_MESSAGE_TYPE(message)) {
+    case GST_MESSAGE_EOS:
+        break;
+    case GST_MESSAGE_WARNING:
+        gst_message_parse_warning(message, &error, &debug);
+        g_warning("Warning: %d, %s. Debug output: %s", error->code,  error->message, debug);
+        break;
+    case GST_MESSAGE_ERROR:
+        gst_message_parse_error(message, &error, &debug);
+        g_warning("Error: %d, %s. Debug output: %s", error->code,  error->message, debug);
+        break;
+    case GST_MESSAGE_STATE_CHANGED:
+        GstState old_state, new_state;
+        gst_message_parse_state_changed (message, &old_state, &new_state, NULL);
+        g_warning ("[play] Element %s changed state from %s to %s.\n",
+           GST_OBJECT_NAME (message->src),
+           gst_element_state_get_name (old_state),
+           gst_element_state_get_name (new_state));
+        break;
+    case GST_MESSAGE_STREAM_STATUS:
+        GstStreamStatusType status;
+        GstElement *owner;
+        gst_message_parse_stream_status(message, &status, &owner);
+        g_warning ("[play] Element %s(%s) changed stream status to %d.\n",
+           GST_OBJECT_NAME (owner),
+           GST_OBJECT_NAME (message->src), status);
+        break;
+
+    case GST_MESSAGE_LATENCY:
+        g_warning ("[play] Element %s requested latency, recaltulating...\n",
+           GST_OBJECT_NAME (message->src));
+        gst_bin_recalculate_latency(GST_BIN(data));
+        break;
+
+    default:
+        break;
+    }
+
+    //FIXME deref error and debug
+    return TRUE;
+}
+
+
diff --git a/src/ContentsInjectedBundle/audio/AudioLiveInputPipeline.cpp b/src/ContentsInjectedBundle/audio/AudioLiveInputPipeline.cpp
index 609ef49..60383fa 100644
--- a/src/ContentsInjectedBundle/audio/AudioLiveInputPipeline.cpp
+++ b/src/ContentsInjectedBundle/audio/AudioLiveInputPipeline.cpp
@@ -23,6 +23,9 @@
 
 #include "AudioLiveInputPipeline.h"
 
+#define AUDIO_ENABLE_PIPELINE_MSG_DUMP
+//#define AUDIO_FAKE_INPUT
+
 GstCaps* getGstAudioCaps(int, float);
 static void onGStreamerDeinterleavePadAddedCallback(GstElement*, GstPad*, AudioLiveInputPipeline*);
 static void onGStreamerDeinterleaveReadyCallback(GstElement*, AudioLiveInputPipeline*);
@@ -176,6 +179,7 @@ GstStateChangeReturn AudioLiveInputPipeline::start()
 }
 
 //#define AUDIO_FAKE_INPUT
+
 void AudioLiveInputPipeline::buildInputPipeline()
 {
     // Sub pipeline looks like:
@@ -183,6 +187,13 @@ void AudioLiveInputPipeline::buildInputPipeline()
     g_print("*** configuring audio input...");
     m_pipeline = gst_pipeline_new("live-input");
 
+#ifdef AUDIO_ENABLE_PIPELINE_MSG_DUMP
+    GstBus* bus = gst_pipeline_get_bus(GST_PIPELINE(m_pipeline));
+    assert(bus);
+    gst_bus_add_signal_watch(bus);
+    g_signal_connect(bus, "message", G_CALLBACK(messageCallback), m_pipeline);
+#endif
+
 #ifndef AUDIO_FAKE_INPUT
     GstElement *source = gst_element_factory_make("pulsesrc", "liveinputsrc");
     g_object_set(source, "blocksize", (gint64)1024, NULL);
@@ -195,10 +206,10 @@ void AudioLiveInputPipeline::buildInputPipeline()
     g_object_set(source, "buffer-time", (gint64) 1451, NULL);
     g_object_set(source, "latency-time", (guint64) 1451, NULL);
 #endif
-
     m_source = source;
 
     GstElement* audioConvert  = gst_element_factory_make("audioconvert", 0);
+
     GstElement* capsFilter = gst_element_factory_make("capsfilter", 0);
     m_deInterleave = gst_element_factory_make("deinterleave", "deinterleave");
 
@@ -248,3 +259,52 @@ static void onGStreamerDeinterleaveReadyCallback(GstElement*, AudioLiveInputPipe
 {
     reader->deinterleavePadsConfigured();
 }
+
+#ifdef AUDIO_ENABLE_PIPELINE_MSG_DUMP
+static gboolean messageCallback(GstBus*, GstMessage* message, GstElement* data)
+{
+    GError* error = 0;
+    gchar* debug = 0;
+
+    switch (GST_MESSAGE_TYPE(message)) {
+    case GST_MESSAGE_EOS:
+        break;
+    case GST_MESSAGE_WARNING:
+        gst_message_parse_warning(message, &error, &debug);
+        g_warning("Warning: %d, %s. Debug output: %s", error->code,  error->message, debug);
+        break;
+    case GST_MESSAGE_ERROR:
+        gst_message_parse_error(message, &error, &debug);
+        g_warning("Error: %d, %s. Debug output: %s", error->code,  error->message, debug);
+        break;
+    case GST_MESSAGE_STATE_CHANGED:
+        GstState old_state, new_state;
+        gst_message_parse_state_changed (message, &old_state, &new_state, NULL);
+        g_warning ("[input] Element %s changed state from %s to %s.\n",
+           GST_OBJECT_NAME (message->src),
+           gst_element_state_get_name (old_state),
+           gst_element_state_get_name (new_state));
+        break;
+    case GST_MESSAGE_STREAM_STATUS:
+        GstStreamStatusType status;
+        GstElement *owner;
+        gst_message_parse_stream_status(message, &status, &owner);
+        g_warning ("[input] Element %s(%s) changed stream status to %d.\n",
+           GST_OBJECT_NAME (owner),
+           GST_OBJECT_NAME (message->src), status);
+        break;
+
+    case GST_MESSAGE_LATENCY:
+        g_warning ("[input] Element %s requested latency, recaltulating...\n",
+           GST_OBJECT_NAME (message->src));
+        gst_bin_recalculate_latency(GST_BIN(data));
+        break;
+
+    default:
+        break;
+    }
+
+    //FIXME deref error and debug
+    return TRUE;
+}
+#endif
diff --git a/src/ContentsInjectedBundle/audio/WebKitWebAudioSourceGStreamer.cpp b/src/ContentsInjectedBundle/audio/WebKitWebAudioSourceGStreamer.cpp
index 5709892..ce22817 100644
--- a/src/ContentsInjectedBundle/audio/WebKitWebAudioSourceGStreamer.cpp
+++ b/src/ContentsInjectedBundle/audio/WebKitWebAudioSourceGStreamer.cpp
@@ -356,6 +356,16 @@ static void webKitWebAudioSrcGetProperty(GObject* object, guint propertyId, GVal
     }
 }
 
+//#define _ENABLE_WEBAUDIO_ROUTING 0
+#define DUMP_BUFFER(buff, label, num) {         \
+    fprintf(stdout, "%s -- { ", label);         \
+    /*for(register int i = 0; i < num; ++i) {*/ \
+    for(register int i = 0; i < 12; ++i) {      \
+        fprintf(stdout, "%f, ", buff[i]);       \
+    }                                           \
+    fprintf(stdout, "... }\n");                 \
+}
+
 static inline float* mapBuffer(GstBuffer* buffer) {
     float * ret = 0;
 #ifdef GST_API_VERSION_1
@@ -369,6 +379,9 @@ static inline float* mapBuffer(GstBuffer* buffer) {
     return ret;
 }
 
+#define AUDIO_ENABLE_LIVE_INPUT
+//#define AUDIO_BYPASS_WEBKIT // bypass webkit
+
 static void webKitWebAudioSrcLoop(WebKitWebAudioSrc* src)
 {
     WebKitWebAudioSourcePrivate* priv = src->priv;
@@ -388,6 +401,10 @@ static void webKitWebAudioSrcLoop(WebKitWebAudioSrc* src)
     float** sourceData = NULL;
     GSList* inputBufferList = 0;
     Nix::Vector<float*> audioDataVector((size_t) 2);
+
+#ifdef AUDIO_ENABLE_LIVE_INPUT
+    //GstClockTime ini, end;
+    //ini = gst_clock_get_time(GST_ELEMENT_GET_CLOCK(src));
     Nix::Vector<float*> sourceDataVector((size_t) 2);
 
     // collect input data
@@ -404,10 +421,33 @@ static void webKitWebAudioSrcLoop(WebKitWebAudioSrc* src)
     for(i = 0; inbufIt != NULL; ++i, inbufIt = g_slist_next(inbufIt)) {
         inbuf = static_cast<GstBuffer*>(inbufIt->data);
         sourceData[i] = mapBuffer(inbuf);
+
+#ifdef AUDIO_BYPASS_WEBKIT
+        // Forcing chaining the buffer bypassing webkit processing
+        // to achieve that, also uncomment #if 0/#endif bellow...
+        GstPad* pad = static_cast<GstPad*>(g_slist_nth_data(priv->pads, i));
+        GstFlowReturn ret = gst_pad_chain(pad, inbuf);
+        if (ret != GST_FLOW_OK) {
+            GST_ELEMENT_ERROR(src, CORE, PAD, ("Internal WebAudioSrc error"), ("Failed to push buffer on %s", GST_DEBUG_PAD_NAME(pad)));
+        }
+    }
+    if (inputBufferList)
+        g_slist_free(inputBufferList);
+    return;
+
+#else
     }
     sourceDataVector[0] = sourceData[0];
     sourceDataVector[1] = sourceData[1];
 
+    //end = gst_clock_get_time(GST_ELEMENT_GET_CLOCK(src));
+    //GST_WARNING_OBJECT(src, "got input buffers - time: %ld nanosecs\n", (end-ini));
+#endif // bypass webkit
+
+#else
+    Nix::Vector<float*> sourceDataVector;
+#endif // enable live-input
+
     unsigned bufferSize = priv->framesToPull * sizeof(float);
     GSList* channelBufferList = 0;
     GstBuffer* channelBuffer;
